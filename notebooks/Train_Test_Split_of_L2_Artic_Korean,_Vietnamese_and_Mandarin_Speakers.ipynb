{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Please download the data from L2 Artic site"
      ],
      "metadata": {
        "id": "Lsc7k90rS6VL"
      },
      "id": "Lsc7k90rS6VL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2704ef9",
      "metadata": {
        "id": "c2704ef9"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import random\n",
        "import unittest\n",
        "import shutil\n",
        "random.seed(10)\n",
        "input_folder = r\"C:\\Users\\isabe\\Downloads\\l2 artic dataset\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check if all the folders have the same files that are manually annotated\n",
        "and the same files that are not manually annotated\n",
        "If this is true, it is easier to split"
      ],
      "metadata": {
        "id": "uJDyI8m4S-ap"
      },
      "id": "uJDyI8m4S-ap"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b501f9a",
      "metadata": {
        "id": "7b501f9a",
        "outputId": "334d5ec2-c98f-437b-b889-343c446cbe3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample folder:  C:\\Users\\isabe\\Downloads\\l2 artic dataset\\BWC\n",
            "Comparison folder:  C:\\Users\\isabe\\Downloads\\l2 artic dataset\\HJK\n",
            "\n",
            "In C:\\Users\\isabe\\Downloads\\l2 artic dataset\\HJK but not in C:\\Users\\isabe\\Downloads\\l2 artic dataset\\BWC\n",
            "{'arctic_a0148', 'arctic_a0233', 'arctic_b0469', 'arctic_b0019', 'arctic_a0384', 'arctic_b0192', 'arctic_b0047', 'arctic_b0068', 'arctic_a0143', 'arctic_a0379', 'arctic_a0145', 'arctic_b0238', 'arctic_b0355', 'arctic_b0425', 'arctic_b0304', 'arctic_a0375', 'arctic_b0518', 'arctic_a0378', 'arctic_a0542', 'arctic_a0168', 'arctic_a0416', 'arctic_b0215', 'arctic_b0315', 'arctic_a0144', 'arctic_a0442', 'arctic_a0475', 'arctic_a0271', 'arctic_b0266', 'arctic_a0178', 'arctic_b0503', 'arctic_b0197', 'arctic_b0225', 'arctic_b0342', 'arctic_a0258', 'arctic_a0364', 'arctic_b0143', 'arctic_b0386', 'arctic_a0369', 'arctic_b0022', 'arctic_a0303', 'arctic_a0260', 'arctic_b0320', 'arctic_b0201', 'arctic_b0106', 'arctic_b0530', 'arctic_a0345', 'arctic_a0272', 'arctic_a0209', 'arctic_a0495', 'arctic_a0365'}\n",
            "\n",
            "In C:\\Users\\isabe\\Downloads\\l2 artic dataset\\BWC but not in C:\\Users\\isabe\\Downloads\\l2 artic dataset\\HJK\n",
            "{'arctic_b0142', 'arctic_b0251', 'arctic_a0575', 'arctic_b0393', 'arctic_b0418', 'arctic_b0380', 'arctic_b0465', 'arctic_b0430', 'arctic_a0536', 'arctic_b0189', 'arctic_a0519', 'arctic_b0026', 'arctic_b0509', 'arctic_b0185', 'arctic_b0048', 'arctic_b0323', 'arctic_b0074', 'arctic_b0461', 'arctic_b0479', 'arctic_a0576', 'arctic_b0282', 'arctic_b0165', 'arctic_a0434', 'arctic_b0483', 'arctic_b0400', 'arctic_b0422', 'arctic_b0385', 'arctic_a0515', 'arctic_b0531', 'arctic_a0549', 'arctic_b0140', 'arctic_b0527', 'arctic_b0476', 'arctic_b0415', 'arctic_b0366', 'arctic_b0288', 'arctic_b0456', 'arctic_b0358', 'arctic_b0004', 'arctic_a0335', 'arctic_b0481', 'arctic_b0416', 'arctic_b0488', 'arctic_a0571', 'arctic_a0245', 'arctic_b0203', 'arctic_b0402', 'arctic_b0075', 'arctic_a0225', 'arctic_a0459'}\n"
          ]
        },
        {
          "ename": "AssertionError",
          "evalue": "There are different files annotated for different speakers",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-55-be3ccebdbe16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"\\nIn {sample_folder} but not in {folder}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexisting_manual_annotation_filenames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_manual_annotation_filenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mexisting_manual_annotation_filenames\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0munique_manual_annotation_filenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"There are different files annotated for different speakers\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Manual annotation filenames are all the same!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAssertionError\u001b[0m: There are different files annotated for different speakers"
          ]
        }
      ],
      "source": [
        "# check if all manual annotation filenames are the same\n",
        "folders = glob.glob(os.path.join(input_folder, \"*\"))\n",
        "sample_folder = folders[0]\n",
        "print(\"Sample folder: \", sample_folder)\n",
        "sample_manual_annotations = glob.glob(os.path.join(sample_folder, \"annotation\", \"*.TextGrid\"))\n",
        "sample_manual_annotations = [path.split(\"\\\\\")[-1][:-9] for path in sample_manual_annotations]\n",
        "existing_manual_annotation_filenames = set(sample_manual_annotations)\n",
        "for folder in folders[1:]:\n",
        "    print(\"Comparison folder: \", folder)\n",
        "    manual_annotations = glob.glob(os.path.join(folder, \"annotation\", \"*.TextGrid\"))\n",
        "    manual_annotations = [path.split(\"\\\\\")[-1][:-9]  for path in manual_annotations]\n",
        "    unique_manual_annotation_filenames = set(manual_annotations)\n",
        "    print(f\"\\nIn {folder} but not in {sample_folder}\")\n",
        "    print(unique_manual_annotation_filenames.difference(existing_manual_annotation_filenames))\n",
        "    print(f\"\\nIn {sample_folder} but not in {folder}\")\n",
        "    print(existing_manual_annotation_filenames.difference(unique_manual_annotation_filenames))\n",
        "    assert existing_manual_annotation_filenames == unique_manual_annotation_filenames, \"There are different files annotated for different speakers\"\n",
        "\n",
        "print(\"Manual annotation filenames are all the same!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the total number of files per folder can differ because some speakers\n",
        "did not speak some audios / due to recording issues so audio was omitted\n",
        "\n",
        "Obtain filenames in test and filenames in train for each folder to save\n",
        "to a dictionary with key being folder path and value being {\"test\": [...], \"train\":[...]"
      ],
      "metadata": {
        "id": "LcqeUsuwTGQt"
      },
      "id": "LcqeUsuwTGQt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4632330",
      "metadata": {
        "id": "d4632330",
        "outputId": "3508744a-b639-4d83-dd13-f731b8e780d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\BWC\n",
            "Total number of files with manual annotations: 150\n",
            "30 files with manual annotation in test and 120 in train\n",
            "Total number of files: 1130\n",
            "Total number of files without manual annotations: 980\n",
            "196 files with no manual annotation in test and 784 in train\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\HJK\n",
            "Total number of files with manual annotations: 150\n",
            "30 files with manual annotation in test and 120 in train\n",
            "Total number of files: 1131\n",
            "Total number of files without manual annotations: 981\n",
            "196 files with no manual annotation in test and 785 in train\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\HKK\n",
            "Total number of files with manual annotations: 150\n",
            "30 files with manual annotation in test and 120 in train\n",
            "Total number of files: 1131\n",
            "Total number of files without manual annotations: 981\n",
            "196 files with no manual annotation in test and 785 in train\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\HQTV\n",
            "Total number of files with manual annotations: 150\n",
            "30 files with manual annotation in test and 120 in train\n",
            "Total number of files: 1132\n",
            "Total number of files without manual annotations: 982\n",
            "196 files with no manual annotation in test and 786 in train\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\LXC\n",
            "Total number of files with manual annotations: 150\n",
            "30 files with manual annotation in test and 120 in train\n",
            "Total number of files: 1131\n",
            "Total number of files without manual annotations: 981\n",
            "196 files with no manual annotation in test and 785 in train\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\NCC\n",
            "Total number of files with manual annotations: 150\n",
            "30 files with manual annotation in test and 120 in train\n",
            "Total number of files: 1131\n",
            "Total number of files without manual annotations: 981\n",
            "196 files with no manual annotation in test and 785 in train\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\PNV\n",
            "Total number of files with manual annotations: 150\n",
            "30 files with manual annotation in test and 120 in train\n",
            "Total number of files: 1132\n",
            "Total number of files without manual annotations: 982\n",
            "196 files with no manual annotation in test and 786 in train\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\THV\n",
            "Total number of files with manual annotations: 150\n",
            "30 files with manual annotation in test and 120 in train\n",
            "Total number of files: 1132\n",
            "Total number of files without manual annotations: 982\n",
            "196 files with no manual annotation in test and 786 in train\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\TLV\n",
            "Total number of files with manual annotations: 150\n",
            "30 files with manual annotation in test and 120 in train\n",
            "Total number of files: 1132\n",
            "Total number of files without manual annotations: 982\n",
            "196 files with no manual annotation in test and 786 in train\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\TXHC\n",
            "Total number of files with manual annotations: 150\n",
            "30 files with manual annotation in test and 120 in train\n",
            "Total number of files: 1132\n",
            "Total number of files without manual annotations: 982\n",
            "196 files with no manual annotation in test and 786 in train\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\YDCK\n",
            "Total number of files with manual annotations: 150\n",
            "30 files with manual annotation in test and 120 in train\n",
            "Total number of files: 1131\n",
            "Total number of files without manual annotations: 981\n",
            "196 files with no manual annotation in test and 785 in train\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\YKWK\n",
            "Total number of files with manual annotations: 150\n",
            "30 files with manual annotation in test and 120 in train\n",
            "Total number of files: 1131\n",
            "Total number of files without manual annotations: 981\n",
            "196 files with no manual annotation in test and 785 in train\n"
          ]
        }
      ],
      "source": [
        "input_folder = r\"C:\\Users\\isabe\\Downloads\\l2 artic dataset\"\n",
        "folder_to_filename_dict = {}\n",
        "\n",
        "for folder in glob.glob(os.path.join(input_folder, \"*\")):\n",
        "    print(folder)\n",
        "    output_folder = folder.replace(\"l2 artic dataset\", \"l2 artic dataset split\")\n",
        "\n",
        "    # splits file with manual annotations first\n",
        "    manual_annotations = glob.glob(os.path.join(folder, \"annotation\", \"*.TextGrid\"))\n",
        "    print(f\"Total number of files with manual annotations: {len(manual_annotations)}\")\n",
        "    manual_annotations = [path.split(\"\\\\\")[-1][:-9] for path in manual_annotations]\n",
        "    test_manual = random.sample(manual_annotations, k=round(len(manual_annotations) * 0.2))\n",
        "    train_manual = [path for path in manual_annotations if path not in test_manual]\n",
        "    print(f\"{len(test_manual)} files with manual annotation in test and {len(train_manual)} in train\")\n",
        "\n",
        "    # split files without manual annotations\n",
        "    wav = glob.glob(os.path.join(folder, \"wav\", \"*.wav\"))\n",
        "    all_filenames = [file.split(\"\\\\\")[-1][:-4] for file in wav]\n",
        "    print(f\"Total number of files: {len(all_filenames)}\")\n",
        "    files_without_manual_annotation = [file for file in all_filenames if file not in manual_annotations]\n",
        "    print(f\"Total number of files without manual annotations: {len(files_without_manual_annotation)}\")\n",
        "    test_without_manual = random.sample(files_without_manual_annotation, k=round(len(files_without_manual_annotation) * 0.2))\n",
        "    train_without_manual = [path for path in files_without_manual_annotation if path not in test_without_manual]\n",
        "    print(f\"{len(test_without_manual)} files with no manual annotation in test and {len(train_without_manual)} in train\")\n",
        "\n",
        "    # combine to form test and train\n",
        "    test = test_manual + test_without_manual\n",
        "    train = train_manual + train_without_manual\n",
        "\n",
        "    # sanity checks\n",
        "    assert(len(test) + len(train) == len(all_filenames))\n",
        "    has_overlap = set(test_manual) & set(train_manual)\n",
        "    assert(not has_overlap)\n",
        "    has_overlap = set(test_without_manual) & set(train_without_manual)\n",
        "    assert(not has_overlap)\n",
        "    has_overlap = set(test_manual) & set(test_without_manual)\n",
        "    assert(not has_overlap)\n",
        "    has_overlap = set(train_manual) & set(train_without_manual)\n",
        "    assert(not has_overlap)\n",
        "    has_overlap = set(test) & set(train)\n",
        "    assert(not has_overlap)\n",
        "\n",
        "    # save result\n",
        "    folder_to_filename_dict[folder] = {\"test\":test, \"train\":train}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the files into new folders based on their split"
      ],
      "metadata": {
        "id": "o_dSJLCkTFGA"
      },
      "id": "o_dSJLCkTFGA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6175734b",
      "metadata": {
        "id": "6175734b",
        "outputId": "07230de1-741c-46ef-840e-9bbe6c93dfd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\BWC\n",
            "Train folder copying is complete\n",
            "Test folder copying is complete\n",
            "set()\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\HJK\n",
            "Train folder copying is complete\n",
            "Test folder copying is complete\n",
            "set()\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\HKK\n",
            "Train folder copying is complete\n",
            "Test folder copying is complete\n",
            "set()\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\HQTV\n",
            "Train folder copying is complete\n",
            "Test folder copying is complete\n",
            "set()\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\LXC\n",
            "Train folder copying is complete\n",
            "Test folder copying is complete\n",
            "set()\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\NCC\n",
            "Train folder copying is complete\n",
            "Test folder copying is complete\n",
            "set()\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\PNV\n",
            "Train folder copying is complete\n",
            "Test folder copying is complete\n",
            "set()\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\THV\n",
            "Train folder copying is complete\n",
            "Test folder copying is complete\n",
            "set()\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\TLV\n",
            "Train folder copying is complete\n",
            "Test folder copying is complete\n",
            "set()\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\TXHC\n",
            "Train folder copying is complete\n",
            "Test folder copying is complete\n",
            "set()\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\YDCK\n",
            "Train folder copying is complete\n",
            "Test folder copying is complete\n",
            "set()\n",
            "C:\\Users\\isabe\\Downloads\\l2 artic dataset\\YKWK\n",
            "Train folder copying is complete\n",
            "Test folder copying is complete\n",
            "set()\n"
          ]
        }
      ],
      "source": [
        "folder_to_extension_mapping = {\"wav\": \".wav\", \"transcript\":\".txt\", \"textgrid\":\".TextGrid\", \"annotation\":\".TextGrid\"}\n",
        "for folder_path, split_details in folder_to_filename_dict.items():\n",
        "    print(folder_path)\n",
        "    test_filenames, train_filenames = split_details[\"test\"], split_details[\"train\"]\n",
        "    train_split_folder_path = os.path.join(folder_path, \"train\").replace(\"l2 artic dataset\", \"l2 artic dataset split\")\n",
        "    for filename in train_filenames:\n",
        "        for inner_folder, extension in folder_to_extension_mapping.items():\n",
        "            # check if the file is present in src\n",
        "            full_filename = filename+extension\n",
        "            src = os.path.join(folder_path, inner_folder, full_filename)\n",
        "            if os.path.exists(src):\n",
        "                dest_folder = os.path.join(train_split_folder_path, inner_folder)\n",
        "                dest = os.path.join(dest_folder, full_filename)\n",
        "                if not os.path.exists(dest_folder):\n",
        "                    os.makedirs(dest_folder)\n",
        "                shutil.copyfile(src, dest)\n",
        "    print(\"Train folder copying is complete\")\n",
        "\n",
        "    test_split_folder_path = os.path.join(folder_path, \"test\").replace(\"l2 artic dataset\", \"l2 artic dataset split\")\n",
        "    for filename in test_filenames:\n",
        "        for inner_folder, extension in folder_to_extension_mapping.items():\n",
        "            # check if the file is present in src\n",
        "            full_filename = filename+extension\n",
        "            src = os.path.join(folder_path, inner_folder, full_filename)\n",
        "            if os.path.exists(src):\n",
        "                dest_folder = os.path.join(test_split_folder_path, inner_folder)\n",
        "                dest = os.path.join(dest_folder, full_filename)\n",
        "                if not os.path.exists(dest_folder):\n",
        "                    os.makedirs(dest_folder)\n",
        "                shutil.copyfile(src, dest)\n",
        "    print(\"Test folder copying is complete\")\n",
        "\n",
        "    # check that transcript, textgrid and annotations folder have same files\n",
        "    for split_folder_path in [train_split_folder_path, test_split_folder_path]:\n",
        "        transcript_files = glob.glob(os.path.join(split_folder_path, \"transcript\", \"*.txt\"))\n",
        "        transcript_filenames = [path.split(\"\\\\\")[-1][:-4] for path in transcript_files]\n",
        "        textgrid_files = glob.glob(os.path.join(split_folder_path, \"textgrid\", \"*.TextGrid\"))\n",
        "        textgrid_filenames = [path.split(\"\\\\\")[-1][:-9] for path in textgrid_files]\n",
        "        wav_files = glob.glob(os.path.join(split_folder_path, \"wav\", \"*.wav\"))\n",
        "        wav_filenames = [path.split(\"\\\\\")[-1][:-4] for path in wav_files]\n",
        "        assert(len(transcript_filenames) == len(textgrid_filenames) == len(wav_filenames))\n",
        "        assert(set(transcript_filenames) == set(textgrid_filenames) == set(wav_filenames))\n",
        "\n",
        "    # check for any data loss\n",
        "    all_train_files = [path.split(\"\\\\\")[-1][:-4] for path in glob.glob(os.path.join(train_split_folder_path, \"wav\", \"*.wav\"))]\n",
        "    assert(set(all_train_files) == set(train_filenames))\n",
        "    all_test_files = [path.split(\"\\\\\")[-1][:-4] for path in glob.glob(os.path.join(test_split_folder_path, \"wav\", \"*.wav\"))]\n",
        "    assert(set(all_test_files) == set(test_filenames))\n",
        "\n",
        "    # check the annations folder adds up to what is expected\n",
        "    train_annotation_files = glob.glob(os.path.join(train_split_folder_path, \"annotation\", \"*.TextGrid\"))\n",
        "    test_annotation_files = glob.glob(os.path.join(test_split_folder_path, \"annotation\", \"*.TextGrid\"))\n",
        "    assert(len(train_annotation_files) == 120)\n",
        "    assert(len(test_annotation_files) == 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4ec9e05",
      "metadata": {
        "id": "d4ec9e05"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}